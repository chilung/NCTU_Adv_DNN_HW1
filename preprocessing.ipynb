{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './cs-t0828-2020-hw1'\n",
    "train_src = 'training_data/training_data'\n",
    "test_src = 'testing_data/testing_data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> generate train file list: images.csv\n",
      "train file directory: ./cs-t0828-2020-hw1\\training_data/training_data\n",
      "number of files: 11185\n",
      "      Image ID Image File Name\n",
      "0       000001      000001.jpg\n",
      "1       000002      000002.jpg\n",
      "2       000003      000003.jpg\n",
      "3       000007      000007.jpg\n",
      "4       000009      000009.jpg\n",
      "...        ...             ...\n",
      "11180   016179      016179.jpg\n",
      "11181   016182      016182.jpg\n",
      "11182   016183      016183.jpg\n",
      "11183   016184      016184.jpg\n",
      "11184   016185      016185.jpg\n",
      "\n",
      "[11185 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print('\\n==> generate train file list: {}'.format('images.csv'))\n",
    "print('train file directory: {}'.format(os.path.join(root_path, train_src)))\n",
    "\n",
    "img_fn_list = os.listdir(os.path.join(root_path, train_src))\n",
    "print('number of files: {}'.format(len(img_fn_list)))\n",
    "#print(img_fn_list)\n",
    "\n",
    "images = [[re.split(\".jpg\", img_fn)[0], img_fn] for img_fn in img_fn_list]\n",
    "images.sort()\n",
    "#print(images)\n",
    "\n",
    "dfObj = pd.DataFrame(images, columns=['Image ID', 'Image File Name'])\n",
    "print(dfObj)\n",
    "dfObj.to_csv(os.path.join(root_path, 'images.csv'), index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> generate test file list: test_images.csv\n",
      "test file directory: ./cs-t0828-2020-hw1\\testing_data/testing_data\n",
      "number of files: 5000\n",
      "     Image ID Image File Name\n",
      "0      000004      000004.jpg\n",
      "1      000005      000005.jpg\n",
      "2      000006      000006.jpg\n",
      "3      000008      000008.jpg\n",
      "4      000019      000019.jpg\n",
      "...       ...             ...\n",
      "4995   016172      016172.jpg\n",
      "4996   016175      016175.jpg\n",
      "4997   016176      016176.jpg\n",
      "4998   016180      016180.jpg\n",
      "4999   016181      016181.jpg\n",
      "\n",
      "[5000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print('\\n==> generate test file list: {}'.format('test_images.csv'))\n",
    "print('test file directory: {}'.format(os.path.join(root_path, test_src)))\n",
    "\n",
    "img_fn_list = os.listdir(os.path.join(root_path, test_src))\n",
    "print('number of files: {}'.format(len(img_fn_list)))\n",
    "#print(img_fn_list)\n",
    "\n",
    "images = [[re.split(\".jpg\", img_fn)[0], img_fn] for img_fn in img_fn_list]\n",
    "images.sort()\n",
    "#print(images)\n",
    "\n",
    "dfObj = pd.DataFrame(images, columns=['Image ID', 'Image File Name'])\n",
    "print(dfObj)\n",
    "dfObj.to_csv(os.path.join(root_path, 'test_images.csv'), index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                                label\n",
      "0       9350          Ford F-150 Regular Cab 2007\n",
      "1       2645                      BMW X6 SUV 2012\n",
      "2       2267              BMW 1 Series Coupe 2012\n",
      "3       8553              Fisker Karma Sedan 2012\n",
      "4       6990  Dodge Ram Pickup 3500 Crew Cab 2010\n",
      "...      ...                                  ...\n",
      "11180    184                  Acura TL Sedan 2012\n",
      "11181   5863          Chevrolet Malibu Sedan 2007\n",
      "11182   2482        BMW 6 Series Convertible 2007\n",
      "11183  14926            Suzuki Kizashi Sedan 2012\n",
      "11184   2927              BMW M6 Convertible 2010\n",
      "\n",
      "[11185 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "training_labels_csv_filename = 'training_labels.csv'\n",
    "training_labels_pd = pd.read_csv(os.path.join(root_path, training_labels_csv_filename))\n",
    "print(training_labels_pd)\n",
    "mycar = training_labels_pd.values.tolist()\n",
    "mycar.sort()\n",
    "#print(mycar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = list(set([img_brand for img_idx, img_brand in mycar]))\n",
    "brands.sort()\n",
    "#print(len(brands))\n",
    "#print(brands)\n",
    "\n",
    "class_label = [[idx, brand] for idx, brand in enumerate(brands)]\n",
    "#print(len(class_label))\n",
    "#print(class_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> generate class file, containing class id and class name: class.csv\n",
      "     Class ID                       Car Brand\n",
      "0           0      AM General Hummer SUV 2000\n",
      "1           1       Acura Integra Type R 2001\n",
      "2           2             Acura RL Sedan 2012\n",
      "3           3             Acura TL Sedan 2012\n",
      "4           4            Acura TL Type-S 2008\n",
      "..        ...                             ...\n",
      "191       191  Volkswagen Golf Hatchback 2012\n",
      "192       192            Volvo 240 Sedan 1993\n",
      "193       193        Volvo C30 Hatchback 2012\n",
      "194       194             Volvo XC90 SUV 2007\n",
      "195       195   smart fortwo Convertible 2012\n",
      "\n",
      "[196 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print('\\n==> generate class file, containing class id and class name: {}'.format('class.csv'))\n",
    "dfObj = pd.DataFrame(class_label, columns=['Class ID', 'Car Brand'])\n",
    "print(dfObj)\n",
    "dfObj.to_csv(os.path.join(root_path, 'class.csv'), index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict \n",
    "\n",
    "name_to_id = {} \n",
    "for idx, brand in class_label:\n",
    "    name_to_id[brand] = idx\n",
    "#print(name_to_id)\n",
    "\n",
    "id_to_name = {} \n",
    "for idx, brand in class_label:\n",
    "    id_to_name[idx] = brand\n",
    "#print(id_to_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> generate train label file and transfer train label name to label id: image_class_labels.csv\n",
      "       Image ID  Class ID\n",
      "0             1         0\n",
      "1             2         0\n",
      "2             3         0\n",
      "3             7         0\n",
      "4             9         0\n",
      "...         ...       ...\n",
      "11180     16179       195\n",
      "11181     16182       195\n",
      "11182     16183       195\n",
      "11183     16184       195\n",
      "11184     16185       195\n",
      "\n",
      "[11185 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print('\\n==> generate train label file and transfer train label name to label id: {}'.format('image_class_labels.csv'))\n",
    "image_class_labels = [[img_idx, name_to_id[img_brand]] for img_idx, img_brand in mycar]\n",
    "#print(image_class_labels)\n",
    "\n",
    "dfObj = pd.DataFrame(image_class_labels, columns=['Image ID', 'Class ID'])\n",
    "print(dfObj)\n",
    "dfObj.to_csv(os.path.join(root_path, 'image_class_labels.csv'), index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> generate train / train phase test split with ratio train/tets = 7/1: train_test_split.csv\n",
      "       Image ID  Train Test Split\n",
      "0             1                 1\n",
      "1             2                 1\n",
      "2             3                 1\n",
      "3             7                 1\n",
      "4             9                 1\n",
      "...         ...               ...\n",
      "11180     16179                 1\n",
      "11181     16182                 1\n",
      "11182     16183                 1\n",
      "11183     16184                 0\n",
      "11184     16185                 1\n",
      "\n",
      "[11185 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print('\\n==> generate train / train phase test split with ratio train/tets = 7/1: {}'.format('train_test_split.csv'))\n",
    "train_test_split = []\n",
    "split_ratio = 7+1\n",
    "split = 1\n",
    "for idx, class_label in image_class_labels:\n",
    "    train_test_split.append([idx, 1 if (split%split_ratio) else 0])\n",
    "    split += 1\n",
    "#print(train_test_split)\n",
    "\n",
    "dfObj = pd.DataFrame(train_test_split, columns=['Image ID', 'Train Test Split'])\n",
    "print(dfObj)\n",
    "dfObj.to_csv(os.path.join(root_path, 'train_test_split.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/20201101_142159/train_test.log'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-c88674cba04c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0maccuracy_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./models/20201101_142159/train_test.log\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-c88674cba04c>\u001b[0m in \u001b[0;36maccuracy_log\u001b[1;34m(f_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0maccuracy_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/20201101_142159/train_test.log'"
     ]
    }
   ],
   "source": [
    "def accuracy_log(f_name):\n",
    "\n",
    "    f = open(f_name)\n",
    "    lines = f.readlines()\n",
    "    print(type(lines))\n",
    "\n",
    "    epoch= []\n",
    "    train_acc= []\n",
    "    test_acc= []\n",
    "    for line in lines:\n",
    "        #print(line)\n",
    "        matchObj = re.match(r'epoch:(\\d+) - train loss: (\\d+.\\d+) and train acc: (\\d+.\\d+) total sample: (\\d+)', line)\n",
    "        if matchObj:\n",
    "            #print('{}\\n{}\\n{}\\n{}\\n{}\\n'.format(matchObj.group(0), matchObj.group(1), matchObj.group(2), matchObj.group(3), matchObj.group(4)))\n",
    "            epoch.append(matchObj.group(1))\n",
    "            train_acc.append(matchObj.group(3))\n",
    "        matchObj = re.match(r'epoch:(\\d+) - test loss: (\\d+.\\d+) and test acc: (\\d+.\\d+) total sample: (\\d+)', line)\n",
    "        if matchObj:\n",
    "            #print('{}\\n{}\\n{}\\n{}\\n{}\\n'.format(matchObj.group(0), matchObj.group(1), matchObj.group(2), matchObj.group(3), matchObj.group(4)))\n",
    "            test_acc.append(matchObj.group(3))\n",
    "    for idx in range(len(epoch)):\n",
    "        print(epoch[idx], train_acc[idx], test_acc[idx])\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "    print(np.argmax(train_acc))\n",
    "    test_max_idx = np.argmax(test_acc)\n",
    "    print(epoch[test_max_idx], test_acc[test_max_idx])\n",
    "\n",
    "    sorted_idx = np.argsort(test_acc)[::-1]\n",
    "    print([test_acc[i] for i in sorted_idx])\n",
    "    print([epoch[i] for i in sorted_idx])\n",
    "    \n",
    "    return\n",
    "\n",
    "accuracy_log(\"./models/20201101_142159/train_test.log\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
