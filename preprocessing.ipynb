{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './cs-t0828-2020-hw1'\n",
    "train_src = 'training_data/training_data'\n",
    "test_src = 'testing_data/testing_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> generate train file list: images.csv\n",
      "train file directory: ./cs-t0828-2020-hw1/training_data/training_data\n",
      "number of files: 11185\n",
      "      Image ID Image File Name\n",
      "0       000001      000001.jpg\n",
      "1       000002      000002.jpg\n",
      "2       000003      000003.jpg\n",
      "3       000007      000007.jpg\n",
      "4       000009      000009.jpg\n",
      "...        ...             ...\n",
      "11180   016179      016179.jpg\n",
      "11181   016182      016182.jpg\n",
      "11182   016183      016183.jpg\n",
      "11183   016184      016184.jpg\n",
      "11184   016185      016185.jpg\n",
      "\n",
      "[11185 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print('\\n==> generate train file list: {}'.format('images.csv'))\n",
    "print('train file directory: {}'.format(os.path.join(root_path, train_src)))\n",
    "\n",
    "img_fn_list = os.listdir(os.path.join(root_path, train_src))\n",
    "print('number of files: {}'.format(len(img_fn_list)))\n",
    "# print(img_fn_list)\n",
    "\n",
    "images = [[re.split(\".jpg\", img_fn)[0], img_fn] for img_fn in img_fn_list]\n",
    "images.sort()\n",
    "# print(images)\n",
    "\n",
    "dfObj = pd.DataFrame(images, columns=['Image ID', 'Image File Name'])\n",
    "print(dfObj)\n",
    "dfObj.to_csv(os.path.join(root_path, 'images.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> generate test file list: test_images.csv\n",
      "test file directory: ./cs-t0828-2020-hw1/testing_data/testing_data\n",
      "number of files: 5000\n",
      "     Image ID Image File Name\n",
      "0      000004      000004.jpg\n",
      "1      000005      000005.jpg\n",
      "2      000006      000006.jpg\n",
      "3      000008      000008.jpg\n",
      "4      000019      000019.jpg\n",
      "...       ...             ...\n",
      "4995   016172      016172.jpg\n",
      "4996   016175      016175.jpg\n",
      "4997   016176      016176.jpg\n",
      "4998   016180      016180.jpg\n",
      "4999   016181      016181.jpg\n",
      "\n",
      "[5000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print('\\n==> generate test file list: {}'.format('test_images.csv'))\n",
    "print('test file directory: {}'.format(os.path.join(root_path, test_src)))\n",
    "\n",
    "img_fn_list = os.listdir(os.path.join(root_path, test_src))\n",
    "print('number of files: {}'.format(len(img_fn_list)))\n",
    "# print(img_fn_list)\n",
    "\n",
    "images = [[re.split(\".jpg\", img_fn)[0], img_fn] for img_fn in img_fn_list]\n",
    "images.sort()\n",
    "# print(images)\n",
    "\n",
    "dfObj = pd.DataFrame(images, columns=['Image ID', 'Image File Name'])\n",
    "print(dfObj)\n",
    "dfObj.to_csv(os.path.join(root_path, 'test_images.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                                label\n",
      "0       9350          Ford F-150 Regular Cab 2007\n",
      "1       2645                      BMW X6 SUV 2012\n",
      "2       2267              BMW 1 Series Coupe 2012\n",
      "3       8553              Fisker Karma Sedan 2012\n",
      "4       6990  Dodge Ram Pickup 3500 Crew Cab 2010\n",
      "...      ...                                  ...\n",
      "11180    184                  Acura TL Sedan 2012\n",
      "11181   5863          Chevrolet Malibu Sedan 2007\n",
      "11182   2482        BMW 6 Series Convertible 2007\n",
      "11183  14926            Suzuki Kizashi Sedan 2012\n",
      "11184   2927              BMW M6 Convertible 2010\n",
      "\n",
      "[11185 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "training_labels_csv_filename = 'training_labels.csv'\n",
    "training_labels_pd = pd.read_csv(os.path.join(root_path, training_labels_csv_filename))\n",
    "print(training_labels_pd)\n",
    "mycar = training_labels_pd.values.tolist()\n",
    "mycar.sort()\n",
    "# print(mycar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = list(set([img_brand for img_idx, img_brand in mycar]))\n",
    "brands.sort()\n",
    "# print(len(brands))\n",
    "# print(brands)\n",
    "\n",
    "class_label = [[idx, brand] for idx, brand in enumerate(brands)]\n",
    "# print(len(class_label))\n",
    "# print(class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> generate class file, containing class id and class name: class.csv\n",
      "     Class ID                       Car Brand\n",
      "0           0      AM General Hummer SUV 2000\n",
      "1           1       Acura Integra Type R 2001\n",
      "2           2             Acura RL Sedan 2012\n",
      "3           3             Acura TL Sedan 2012\n",
      "4           4            Acura TL Type-S 2008\n",
      "..        ...                             ...\n",
      "191       191  Volkswagen Golf Hatchback 2012\n",
      "192       192            Volvo 240 Sedan 1993\n",
      "193       193        Volvo C30 Hatchback 2012\n",
      "194       194             Volvo XC90 SUV 2007\n",
      "195       195   smart fortwo Convertible 2012\n",
      "\n",
      "[196 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print('\\n==> generate class file, containing class id and class name: {}'.\n",
    "      format('class.csv'))\n",
    "dfObj = pd.DataFrame(class_label, columns=['Class ID', 'Car Brand'])\n",
    "print(dfObj)\n",
    "dfObj.to_csv(os.path.join(root_path, 'class.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_id = {}\n",
    "for idx, brand in class_label:\n",
    "    name_to_id[brand] = idx\n",
    "# print(name_to_id)\n",
    "\n",
    "id_to_name = {}\n",
    "for idx, brand in class_label:\n",
    "    id_to_name[idx] = brand\n",
    "# print(id_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> generate train label file and transfer train label name to label id: image_class_labels.csv\n",
      "       Image ID  Class ID\n",
      "0             1         0\n",
      "1             2         0\n",
      "2             3         0\n",
      "3             7         0\n",
      "4             9         0\n",
      "...         ...       ...\n",
      "11180     16179       195\n",
      "11181     16182       195\n",
      "11182     16183       195\n",
      "11183     16184       195\n",
      "11184     16185       195\n",
      "\n",
      "[11185 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print('\\n==> generate train label file and transfer train label name to label id: {}'.format('image_class_labels.csv'))\n",
    "image_class_labels = [[img_idx, name_to_id[img_brand]] for img_idx, img_brand in mycar]\n",
    "# print(image_class_labels)\n",
    "\n",
    "dfObj = pd.DataFrame(image_class_labels, columns=['Image ID', 'Class ID'])\n",
    "print(dfObj)\n",
    "dfObj.to_csv(os.path.join(root_path, 'image_class_labels.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> generate train / train phase test split with ratio train/tets = 7/1: train_test_split.csv\n",
      "       Image ID  Train Test Split\n",
      "0             1                 1\n",
      "1             2                 1\n",
      "2             3                 1\n",
      "3             7                 1\n",
      "4             9                 1\n",
      "...         ...               ...\n",
      "11180     16179                 1\n",
      "11181     16182                 1\n",
      "11182     16183                 1\n",
      "11183     16184                 0\n",
      "11184     16185                 1\n",
      "\n",
      "[11185 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print('\\n==> generate train / train phase test split with ratio train/tets = 7/1: {}'.format('train_test_split.csv'))\n",
    "train_test_split = []\n",
    "split_ratio = 7+1\n",
    "split = 1\n",
    "for idx, class_label in image_class_labels:\n",
    "    train_test_split.append([idx, 1 if (split % split_ratio) else 0])\n",
    "    split += 1\n",
    "# print(train_test_split)\n",
    "\n",
    "dfObj = pd.DataFrame(train_test_split, columns=['Image ID', 'Train Test Split'])\n",
    "print(dfObj)\n",
    "dfObj.to_csv(os.path.join(root_path, 'train_test_split.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "91 0.923 0.826\n",
      "92 0.928 0.833\n",
      "93 0.936 0.846\n",
      "94 0.914 0.808\n",
      "95 0.915 0.824\n",
      "96 0.942 0.848\n",
      "97 0.947 0.858\n",
      "98 0.936 0.837\n",
      "99 0.942 0.851\n",
      "100 0.928 0.823\n",
      "101 0.936 0.842\n",
      "102 0.939 0.836\n",
      "103 0.937 0.835\n",
      "104 0.949 0.855\n",
      "105 0.927 0.831\n",
      "106 0.935 0.845\n",
      "107 0.950 0.849\n",
      "108 0.939 0.834\n",
      "109 0.944 0.848\n",
      "110 0.943 0.851\n",
      "111 0.946 0.849\n",
      "112 0.941 0.838\n",
      "113 0.938 0.839\n",
      "114 0.955 0.863\n",
      "115 0.931 0.835\n",
      "116 0.941 0.839\n",
      "117 0.933 0.837\n",
      "118 0.945 0.856\n",
      "119 0.936 0.823\n",
      "120 0.932 0.838\n",
      "121 0.937 0.845\n",
      "122 0.939 0.829\n",
      "123 0.943 0.847\n",
      "124 0.939 0.840\n",
      "125 0.929 0.842\n",
      "126 0.936 0.823\n",
      "127 0.946 0.847\n",
      "128 0.942 0.842\n",
      "129 0.949 0.853\n",
      "130 0.947 0.855\n",
      "131 0.942 0.836\n",
      "132 0.943 0.851\n",
      "133 0.934 0.842\n",
      "134 0.946 0.853\n",
      "135 0.947 0.845\n",
      "136 0.944 0.844\n",
      "137 0.944 0.849\n",
      "138 0.947 0.825\n",
      "139 0.947 0.846\n",
      "140 0.953 0.851\n",
      "141 0.951 0.845\n",
      "142 0.934 0.834\n",
      "143 0.949 0.853\n",
      "144 0.945 0.840\n",
      "145 0.946 0.845\n",
      "146 0.948 0.857\n",
      "147 0.948 0.848\n",
      "148 0.931 0.823\n",
      "149 0.952 0.851\n",
      "150 0.949 0.846\n",
      "151 0.944 0.852\n",
      "152 0.946 0.852\n",
      "153 0.946 0.847\n",
      "154 0.948 0.853\n",
      "155 0.939 0.838\n",
      "156 0.950 0.838\n",
      "157 0.945 0.838\n",
      "158 0.941 0.844\n",
      "159 0.939 0.831\n",
      "160 0.954 0.856\n",
      "161 0.953 0.848\n",
      "162 0.945 0.835\n",
      "163 0.945 0.845\n",
      "164 0.947 0.841\n",
      "165 0.945 0.839\n",
      "166 0.941 0.830\n",
      "167 0.956 0.852\n",
      "168 0.942 0.839\n",
      "169 0.949 0.848\n",
      "170 0.944 0.831\n",
      "171 0.946 0.831\n",
      "172 0.950 0.843\n",
      "173 0.950 0.857\n",
      "174 0.945 0.835\n",
      "175 0.942 0.833\n",
      "176 0.945 0.830\n",
      "177 0.943 0.843\n",
      "178 0.946 0.839\n",
      "179 0.952 0.848\n",
      "180 0.948 0.836\n",
      "181 0.940 0.830\n",
      "182 0.948 0.841\n",
      "183 0.949 0.848\n",
      "184 0.949 0.842\n",
      "185 0.942 0.840\n",
      "186 0.944 0.830\n",
      "187 0.945 0.837\n",
      "188 0.934 0.831\n",
      "189 0.948 0.838\n",
      "190 0.953 0.857\n",
      "191 0.952 0.843\n",
      "192 0.948 0.848\n",
      "193 0.948 0.853\n",
      "194 0.944 0.852\n",
      "195 0.953 0.840\n",
      "196 0.956 0.847\n",
      "197 0.956 0.858\n",
      "198 0.946 0.848\n",
      "199 0.948 0.830\n",
      "200 0.949 0.833\n",
      "201 0.941 0.826\n",
      "202 0.952 0.840\n",
      "203 0.950 0.845\n",
      "204 0.946 0.834\n",
      "205 0.952 0.843\n",
      "206 0.944 0.835\n",
      "207 0.951 0.841\n",
      "208 0.957 0.857\n",
      "209 0.945 0.845\n",
      "210 0.951 0.835\n",
      "211 0.954 0.845\n",
      "212 0.959 0.853\n",
      "213 0.943 0.833\n",
      "214 0.951 0.861\n",
      "215 0.951 0.836\n",
      "216 0.947 0.840\n",
      "217 0.960 0.852\n",
      "218 0.955 0.849\n",
      "219 0.957 0.847\n",
      "220 0.952 0.844\n",
      "221 0.955 0.856\n",
      "222 0.961 0.852\n",
      "223 0.952 0.853\n",
      "224 0.948 0.838\n",
      "225 0.947 0.820\n",
      "226 0.952 0.849\n",
      "227 0.956 0.849\n",
      "228 0.950 0.837\n",
      "229 0.949 0.841\n",
      "230 0.948 0.835\n",
      "231 0.946 0.843\n",
      "232 0.942 0.840\n",
      "233 0.960 0.850\n",
      "234 0.955 0.847\n",
      "235 0.948 0.842\n",
      "236 0.941 0.837\n",
      "237 0.944 0.830\n",
      "238 0.960 0.835\n",
      "131\n",
      "114 0.863\n",
      "['0.863', '0.861', '0.858', '0.858', '0.857', '0.857', '0.857', '0.857', '0.856', '0.856', '0.856', '0.855', '0.855', '0.853', '0.853', '0.853', '0.853', '0.853', '0.853', '0.853', '0.852', '0.852', '0.852', '0.852', '0.852', '0.852', '0.851', '0.851', '0.851', '0.851', '0.851', '0.850', '0.849', '0.849', '0.849', '0.849', '0.849', '0.849', '0.848', '0.848', '0.848', '0.848', '0.848', '0.848', '0.848', '0.848', '0.848', '0.847', '0.847', '0.847', '0.847', '0.847', '0.847', '0.846', '0.846', '0.846', '0.845', '0.845', '0.845', '0.845', '0.845', '0.845', '0.845', '0.845', '0.845', '0.844', '0.844', '0.844', '0.843', '0.843', '0.843', '0.843', '0.843', '0.842', '0.842', '0.842', '0.842', '0.842', '0.842', '0.841', '0.841', '0.841', '0.841', '0.840', '0.840', '0.840', '0.840', '0.840', '0.840', '0.840', '0.839', '0.839', '0.839', '0.839', '0.839', '0.838', '0.838', '0.838', '0.838', '0.838', '0.838', '0.838', '0.837', '0.837', '0.837', '0.837', '0.837', '0.836', '0.836', '0.836', '0.836', '0.835', '0.835', '0.835', '0.835', '0.835', '0.835', '0.835', '0.835', '0.834', '0.834', '0.834', '0.833', '0.833', '0.833', '0.833', '0.831', '0.831', '0.831', '0.831', '0.831', '0.830', '0.830', '0.830', '0.830', '0.830', '0.830', '0.829', '0.826', '0.826', '0.825', '0.824', '0.823', '0.823', '0.823', '0.823', '0.820', '0.808']\n",
      "['114', '214', '197', '97', '173', '190', '146', '208', '221', '118', '160', '130', '104', '193', '143', '223', '154', '129', '212', '134', '152', '151', '194', '217', '167', '222', '149', '110', '99', '140', '132', '233', '227', '111', '218', '137', '107', '226', '161', '192', '109', '169', '183', '179', '147', '198', '96', '196', '127', '234', '153', '123', '219', '139', '93', '150', '209', '163', '211', '135', '203', '141', '145', '106', '121', '220', '158', '136', '177', '231', '172', '191', '205', '101', '125', '184', '128', '133', '235', '164', '182', '229', '207', '124', '232', '216', '202', '144', '185', '195', '116', '165', '168', '113', '178', '156', '224', '157', '112', '120', '155', '189', '187', '98', '228', '117', '236', '102', '180', '215', '131', '103', '115', '238', '174', '162', '210', '206', '230', '108', '204', '142', '200', '92', '175', '213', '159', '188', '170', '171', '105', '199', '181', '237', '176', '166', '186', '122', '91', '201', '138', '95', '100', '119', '148', '126', '225', '94']\n"
     ]
    }
   ],
   "source": [
    "def accuracy_log(f_name):\n",
    "\n",
    "    f = open(f_name)\n",
    "    lines = f.readlines()\n",
    "    print(type(lines))\n",
    "\n",
    "    epoch = []\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    for line in lines:\n",
    "        # print(line)\n",
    "        matchObj = re.match(r'epoch:(\\d+) - train loss: (\\d+.\\d+) and train acc: (\\d+.\\d+) total sample: (\\d+)', line)\n",
    "        if matchObj:\n",
    "            # print('{}\\n{}\\n{}\\n{}\\n{}\\n'.format(matchObj.group(0), matchObj.group(1), matchObj.group(2), matchObj.group(3), matchObj.group(4)))\n",
    "            epoch.append(matchObj.group(1))\n",
    "            train_acc.append(matchObj.group(3))\n",
    "        matchObj = re.match(r'epoch:(\\d+) - test loss: (\\d+.\\d+) and test acc: (\\d+.\\d+) total sample: (\\d+)', line)\n",
    "        if matchObj:\n",
    "            # print('{}\\n{}\\n{}\\n{}\\n{}\\n'.format(matchObj.group(0), matchObj.group(1), matchObj.group(2), matchObj.group(3), matchObj.group(4)))\n",
    "            test_acc.append(matchObj.group(3))\n",
    "    for idx in range(len(epoch)):\n",
    "        print(epoch[idx], train_acc[idx], test_acc[idx])\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    print(np.argmax(train_acc))\n",
    "    test_max_idx = np.argmax(test_acc)\n",
    "    print(epoch[test_max_idx], test_acc[test_max_idx])\n",
    "\n",
    "    sorted_idx = np.argsort(test_acc)[::-1]\n",
    "    print([test_acc[i] for i in sorted_idx])\n",
    "    print([epoch[i] for i in sorted_idx])\n",
    "\n",
    "    return\n",
    "\n",
    "accuracy_log(\"./models/20201103_235321/train_test.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model check list: ['229.ckpt', '112.ckpt', '184.ckpt', '144.ckpt', '123.ckpt', '199.ckpt', '233.ckpt', '231.ckpt', '185.ckpt', '167.ckpt', '207.ckpt', '170.ckpt', '145.ckpt', '149.ckpt', '111.ckpt', '098.ckpt', '162.ckpt', '146.ckpt', '172.ckpt', '115.ckpt', '213.ckpt', '224.ckpt', '202.ckpt', '134.ckpt', '114.ckpt', '130.ckpt', '235.ckpt', '118.ckpt', '148.ckpt', '215.ckpt', '190.ckpt', '220.ckpt', '182.ckpt', '119.ckpt', '164.ckpt', '116.ckpt', '161.ckpt', '219.ckpt', '222.ckpt', '126.ckpt', '132.ckpt', '188.ckpt', '139.ckpt', '237.ckpt', '178.ckpt', '100.ckpt', '151.ckpt', '160.ckpt', '201.ckpt', '117.ckpt', '198.ckpt', '183.ckpt', '238.ckpt', '212.ckpt', '138.ckpt', '120.ckpt', '217.ckpt', '141.ckpt', '210.ckpt', '176.ckpt', '103.ckpt', '113.ckpt', '226.ckpt', '200.ckpt', '128.ckpt', '094.ckpt', '221.ckpt', '230.ckpt', '095.ckpt', '197.ckpt', '105.ckpt', '101.ckpt', '180.ckpt', 'train_test.log', '223.ckpt', '140.ckpt', '173.ckpt', '131.ckpt', '174.ckpt', '108.ckpt', '106.ckpt', '232.ckpt', '179.ckpt', '107.ckpt', '156.ckpt', '196.ckpt', '204.ckpt', '129.ckpt', '102.ckpt', '206.ckpt', '133.ckpt', '092.ckpt', '205.ckpt', '091.ckpt', '159.ckpt', '209.ckpt', '181.ckpt', '234.ckpt', '136.ckpt', '169.ckpt', '211.ckpt', '152.ckpt', '153.ckpt', '157.ckpt', '121.ckpt', '163.ckpt', '236.ckpt', '168.ckpt', '142.ckpt', '150.ckpt', '227.ckpt', 'log.log', '147.ckpt', '192.ckpt', '099.ckpt', '225.ckpt', '194.ckpt', '203.ckpt', '165.ckpt', '143.ckpt', '125.ckpt', '216.ckpt', '124.ckpt', '208.ckpt', '214.ckpt', '158.ckpt', '137.ckpt', '186.ckpt', '104.ckpt', '109.ckpt', '218.ckpt', '110.ckpt', '171.ckpt', '122.ckpt', '166.ckpt', '154.ckpt', '135.ckpt', '096.ckpt', '228.ckpt', '189.ckpt', '093.ckpt', '191.ckpt', '127.ckpt', '175.ckpt', '187.ckpt', '193.ckpt', '155.ckpt', '195.ckpt', '097.ckpt', '177.ckpt']\n",
      "epoch: 229, train_acc: 0.9491161745172167, test_acc: 0.8412017167381974\n",
      "epoch: 112, train_acc: 0.9406355369367528, test_acc: 0.8383404864091559\n",
      "epoch: 184, train_acc: 0.9492183508736078, test_acc: 0.8419170243204578\n",
      "epoch: 144, train_acc: 0.9451312966179626, test_acc: 0.8397711015736766\n",
      "epoch: 123, train_acc: 0.9428834167773578, test_acc: 0.8469241773962805\n",
      "epoch: 199, train_acc: 0.9475835291713498, test_acc: 0.8297567954220315\n",
      "epoch: 233, train_acc: 0.9600490446510678, test_acc: 0.8497854077253219\n",
      "epoch: 231, train_acc: 0.9456421783999183, test_acc: 0.8426323319027181\n",
      "epoch: 185, train_acc: 0.9419638295698375, test_acc: 0.8404864091559371\n",
      "epoch: 167, train_acc: 0.9561663431082048, test_acc: 0.851931330472103\n",
      "epoch: 207, train_acc: 0.9510575252886482, test_acc: 0.8412017167381974\n",
      "epoch: 170, train_acc: 0.9438030039848779, test_acc: 0.8311874105865522\n",
      "epoch: 145, train_acc: 0.9456421783999183, test_acc: 0.8447782546494993\n",
      "epoch: 149, train_acc: 0.9515684070706039, test_acc: 0.8505007153075823\n",
      "epoch: 111, train_acc: 0.9456421783999183, test_acc: 0.8490701001430615\n",
      "epoch: 98, train_acc: 0.9357310718299785, test_acc: 0.8369098712446352\n",
      "epoch: 162, train_acc: 0.9447225911923981, test_acc: 0.8347639484978541\n",
      "epoch: 146, train_acc: 0.9479922345969143, test_acc: 0.8569384835479256\n",
      "epoch: 172, train_acc: 0.950137938081128, test_acc: 0.8426323319027181\n",
      "epoch: 115, train_acc: 0.931439664861551, test_acc: 0.8347639484978541\n",
      "epoch: 213, train_acc: 0.9431899458465312, test_acc: 0.8333333333333334\n",
      "epoch: 224, train_acc: 0.9475835291713498, test_acc: 0.8383404864091559\n",
      "epoch: 202, train_acc: 0.9517727597833862, test_acc: 0.8404864091559371\n",
      "epoch: 134, train_acc: 0.946255236538265, test_acc: 0.8526466380543634\n",
      "epoch: 114, train_acc: 0.9549402268315111, test_acc: 0.8626609442060086\n",
      "epoch: 130, train_acc: 0.9474813528149586, test_acc: 0.8547925608011445\n",
      "epoch: 235, train_acc: 0.9478900582405232, test_acc: 0.8419170243204578\n",
      "epoch: 118, train_acc: 0.9453356493307449, test_acc: 0.8562231759656652\n",
      "epoch: 148, train_acc: 0.93133748850516, test_acc: 0.8233190271816881\n",
      "epoch: 215, train_acc: 0.9509553489322571, test_acc: 0.8361945636623748\n",
      "epoch: 190, train_acc: 0.953203228772862, test_acc: 0.8569384835479256\n",
      "epoch: 220, train_acc: 0.9522836415653417, test_acc: 0.844062947067239\n",
      "epoch: 182, train_acc: 0.9476857055277409, test_acc: 0.8412017167381974\n",
      "epoch: 119, train_acc: 0.9364463063247165, test_acc: 0.8233190271816881\n",
      "epoch: 164, train_acc: 0.9468682946766118, test_acc: 0.8412017167381974\n",
      "epoch: 116, train_acc: 0.9413507714314907, test_acc: 0.8390557939914163\n",
      "epoch: 161, train_acc: 0.9528966997036886, test_acc: 0.8476394849785408\n",
      "epoch: 219, train_acc: 0.957085930315725, test_acc: 0.8469241773962805\n",
      "epoch: 222, train_acc: 0.9609686318585879, test_acc: 0.851931330472103\n",
      "epoch: 126, train_acc: 0.9356288954735874, test_acc: 0.8226037195994278\n",
      "epoch: 132, train_acc: 0.9433942985593133, test_acc: 0.8512160228898427\n",
      "epoch: 188, train_acc: 0.9343006028405028, test_acc: 0.8311874105865522\n",
      "epoch: 139, train_acc: 0.9466639419638295, test_acc: 0.84620886981402\n",
      "epoch: 237, train_acc: 0.943905180341269, test_acc: 0.8304721030042919\n",
      "epoch: 178, train_acc: 0.946153060181874, test_acc: 0.8390557939914163\n",
      "epoch: 100, train_acc: 0.9277613160314703, test_acc: 0.8226037195994278\n",
      "epoch: 151, train_acc: 0.9437008276284867, test_acc: 0.851931330472103\n",
      "epoch: 160, train_acc: 0.9538162869112088, test_acc: 0.8555078683834049\n",
      "epoch: 201, train_acc: 0.9413507714314907, test_acc: 0.8261802575107297\n",
      "epoch: 117, train_acc: 0.9327679574946357, test_acc: 0.8369098712446352\n",
      "epoch: 198, train_acc: 0.9463574128946561, test_acc: 0.8483547925608012\n",
      "epoch: 183, train_acc: 0.9494227035863901, test_acc: 0.8483547925608012\n",
      "epoch: 238, train_acc: 0.9603555737202412, test_acc: 0.8354792560801144\n",
      "epoch: 212, train_acc: 0.9591294574435476, test_acc: 0.8526466380543634\n",
      "epoch: 138, train_acc: 0.9466639419638295, test_acc: 0.8247496423462088\n",
      "epoch: 120, train_acc: 0.9321548993562889, test_acc: 0.8383404864091559\n",
      "epoch: 217, train_acc: 0.9596403392255032, test_acc: 0.851931330472103\n",
      "epoch: 141, train_acc: 0.9507509962194748, test_acc: 0.8454935622317596\n",
      "epoch: 210, train_acc: 0.9512618780014305, test_acc: 0.8354792560801144\n",
      "epoch: 176, train_acc: 0.9449269439051804, test_acc: 0.8297567954220315\n",
      "epoch: 103, train_acc: 0.9365484826811076, test_acc: 0.8347639484978541\n",
      "epoch: 113, train_acc: 0.9382854807397568, test_acc: 0.8390557939914163\n",
      "epoch: 226, train_acc: 0.951670583426995, test_acc: 0.8490701001430615\n",
      "epoch: 200, train_acc: 0.9491161745172167, test_acc: 0.8333333333333334\n",
      "epoch: 128, train_acc: 0.9421681822826198, test_acc: 0.8419170243204578\n",
      "epoch: 94, train_acc: 0.9144783897006232, test_acc: 0.8075822603719599\n",
      "epoch: 221, train_acc: 0.9549402268315111, test_acc: 0.8562231759656652\n",
      "epoch: 230, train_acc: 0.9476857055277409, test_acc: 0.8354792560801144\n",
      "epoch: 95, train_acc: 0.9148870951261878, test_acc: 0.8240343347639485\n",
      "epoch: 197, train_acc: 0.955553284969858, test_acc: 0.8583690987124464\n",
      "epoch: 105, train_acc: 0.9274547869622969, test_acc: 0.8311874105865522\n",
      "epoch: 101, train_acc: 0.9363441299683253, test_acc: 0.8419170243204578\n",
      "epoch: 180, train_acc: 0.9476857055277409, test_acc: 0.8361945636623748\n",
      "epoch: 223, train_acc: 0.9515684070706039, test_acc: 0.8526466380543634\n",
      "epoch: 140, train_acc: 0.9525901706345151, test_acc: 0.8512160228898427\n",
      "epoch: 173, train_acc: 0.9499335853683457, test_acc: 0.8569384835479256\n",
      "epoch: 131, train_acc: 0.9418616532134464, test_acc: 0.8361945636623748\n",
      "epoch: 174, train_acc: 0.9452334729743538, test_acc: 0.8354792560801144\n",
      "epoch: 108, train_acc: 0.9387963625217125, test_acc: 0.8340486409155937\n",
      "epoch: 106, train_acc: 0.935322366404414, test_acc: 0.8447782546494993\n",
      "epoch: 232, train_acc: 0.941555124144273, test_acc: 0.8404864091559371\n",
      "epoch: 179, train_acc: 0.9518749361397773, test_acc: 0.8483547925608012\n",
      "epoch: 107, train_acc: 0.9499335853683457, test_acc: 0.8490701001430615\n",
      "epoch: 156, train_acc: 0.9498314090119546, test_acc: 0.8383404864091559\n",
      "epoch: 196, train_acc: 0.9561663431082048, test_acc: 0.8469241773962805\n",
      "epoch: 204, train_acc: 0.9464595892510473, test_acc: 0.8340486409155937\n",
      "epoch: 129, train_acc: 0.9494227035863901, test_acc: 0.8533619456366237\n",
      "epoch: 102, train_acc: 0.9391028915908859, test_acc: 0.8361945636623748\n",
      "epoch: 206, train_acc: 0.9438030039848779, test_acc: 0.8354792560801144\n",
      "epoch: 133, train_acc: 0.9338918974149382, test_acc: 0.8419170243204578\n",
      "epoch: 92, train_acc: 0.928374374169817, test_acc: 0.8326180257510729\n",
      "epoch: 205, train_acc: 0.9521814652089506, test_acc: 0.8433476394849786\n",
      "epoch: 91, train_acc: 0.9234699090630428, test_acc: 0.8261802575107297\n",
      "epoch: 159, train_acc: 0.939205067947277, test_acc: 0.8311874105865522\n",
      "epoch: 209, train_acc: 0.9446204148360069, test_acc: 0.8454935622317596\n",
      "epoch: 181, train_acc: 0.9403290078675794, test_acc: 0.8304721030042919\n",
      "epoch: 234, train_acc: 0.9545315214059467, test_acc: 0.8469241773962805\n",
      "epoch: 136, train_acc: 0.9437008276284867, test_acc: 0.844062947067239\n",
      "epoch: 169, train_acc: 0.9494227035863901, test_acc: 0.8476394849785408\n",
      "epoch: 211, train_acc: 0.9535097578420354, test_acc: 0.8454935622317596\n",
      "epoch: 152, train_acc: 0.9457443547563094, test_acc: 0.851931330472103\n",
      "epoch: 153, train_acc: 0.9459487074690917, test_acc: 0.8469241773962805\n",
      "epoch: 157, train_acc: 0.9451312966179626, test_acc: 0.8383404864091559\n",
      "epoch: 121, train_acc: 0.936855011750281, test_acc: 0.8454935622317596\n",
      "epoch: 163, train_acc: 0.9445182384796158, test_acc: 0.8447782546494993\n",
      "epoch: 236, train_acc: 0.9412485950750996, test_acc: 0.8369098712446352\n",
      "epoch: 168, train_acc: 0.9418616532134464, test_acc: 0.8390557939914163\n",
      "epoch: 142, train_acc: 0.9341984264841116, test_acc: 0.8340486409155937\n",
      "epoch: 150, train_acc: 0.9490139981608255, test_acc: 0.84620886981402\n",
      "epoch: 227, train_acc: 0.956370695820987, test_acc: 0.8490701001430615\n",
      "epoch: 147, train_acc: 0.947787881884132, test_acc: 0.8476394849785408\n",
      "epoch: 192, train_acc: 0.947787881884132, test_acc: 0.8476394849785408\n",
      "epoch: 99, train_acc: 0.9421681822826198, test_acc: 0.8512160228898427\n",
      "epoch: 225, train_acc: 0.9472770001021763, test_acc: 0.8204577968526466\n",
      "epoch: 194, train_acc: 0.9442117094104424, test_acc: 0.851931330472103\n",
      "epoch: 203, train_acc: 0.9502401144375192, test_acc: 0.8454935622317596\n",
      "epoch: 165, train_acc: 0.9451312966179626, test_acc: 0.8390557939914163\n",
      "epoch: 143, train_acc: 0.9487074690916522, test_acc: 0.8533619456366237\n",
      "epoch: 125, train_acc: 0.9288852559517727, test_acc: 0.8419170243204578\n",
      "epoch: 216, train_acc: 0.9469704710330029, test_acc: 0.8397711015736766\n",
      "epoch: 124, train_acc: 0.9394094206600593, test_acc: 0.8404864091559371\n",
      "epoch: 208, train_acc: 0.9571881066721161, test_acc: 0.8569384835479256\n",
      "epoch: 214, train_acc: 0.9507509962194748, test_acc: 0.8612303290414879\n",
      "epoch: 158, train_acc: 0.9413507714314907, test_acc: 0.844062947067239\n",
      "epoch: 137, train_acc: 0.9443138857668335, test_acc: 0.8490701001430615\n",
      "epoch: 186, train_acc: 0.9442117094104424, test_acc: 0.8297567954220315\n",
      "epoch: 104, train_acc: 0.9490139981608255, test_acc: 0.8547925608011445\n",
      "epoch: 109, train_acc: 0.9441095330540513, test_acc: 0.8476394849785408\n",
      "epoch: 218, train_acc: 0.9552467559006845, test_acc: 0.8490701001430615\n",
      "epoch: 110, train_acc: 0.9428834167773578, test_acc: 0.8512160228898427\n",
      "epoch: 171, train_acc: 0.9455400020435272, test_acc: 0.8311874105865522\n",
      "epoch: 122, train_acc: 0.9390007152344947, test_acc: 0.829041487839771\n",
      "epoch: 166, train_acc: 0.9407377132931439, test_acc: 0.8297567954220315\n",
      "epoch: 154, train_acc: 0.9475835291713498, test_acc: 0.8526466380543634\n",
      "epoch: 135, train_acc: 0.9471748237457852, test_acc: 0.8447782546494993\n",
      "epoch: 96, train_acc: 0.9420660059262287, test_acc: 0.8476394849785408\n",
      "epoch: 228, train_acc: 0.950137938081128, test_acc: 0.8369098712446352\n",
      "epoch: 189, train_acc: 0.9476857055277409, test_acc: 0.8383404864091559\n",
      "epoch: 93, train_acc: 0.9356288954735874, test_acc: 0.84620886981402\n",
      "epoch: 191, train_acc: 0.9515684070706039, test_acc: 0.8433476394849786\n",
      "epoch: 127, train_acc: 0.946153060181874, test_acc: 0.8469241773962805\n",
      "epoch: 175, train_acc: 0.9424747113517932, test_acc: 0.8326180257510729\n",
      "epoch: 187, train_acc: 0.9448247675487892, test_acc: 0.8369098712446352\n",
      "epoch: 193, train_acc: 0.9476857055277409, test_acc: 0.8533619456366237\n",
      "epoch: 155, train_acc: 0.9394094206600593, test_acc: 0.8383404864091559\n",
      "epoch: 195, train_acc: 0.9526923469909063, test_acc: 0.8397711015736766\n",
      "epoch: 97, train_acc: 0.9468682946766118, test_acc: 0.857653791130186\n",
      "epoch: 177, train_acc: 0.9433942985593133, test_acc: 0.8433476394849786\n",
      "[0.8626609442060086, 0.8612303290414879, 0.8583690987124464, 0.857653791130186, 0.8569384835479256, 0.8569384835479256, 0.8569384835479256, 0.8569384835479256, 0.8562231759656652, 0.8562231759656652, 0.8555078683834049, 0.8547925608011445, 0.8547925608011445, 0.8533619456366237, 0.8533619456366237, 0.8533619456366237, 0.8526466380543634, 0.8526466380543634, 0.8526466380543634, 0.8526466380543634, 0.851931330472103, 0.851931330472103, 0.851931330472103, 0.851931330472103, 0.851931330472103, 0.851931330472103, 0.8512160228898427, 0.8512160228898427, 0.8512160228898427, 0.8512160228898427, 0.8505007153075823, 0.8497854077253219, 0.8490701001430615, 0.8490701001430615, 0.8490701001430615, 0.8490701001430615, 0.8490701001430615, 0.8490701001430615, 0.8483547925608012, 0.8483547925608012, 0.8483547925608012, 0.8476394849785408, 0.8476394849785408, 0.8476394849785408, 0.8476394849785408, 0.8476394849785408, 0.8476394849785408, 0.8469241773962805, 0.8469241773962805, 0.8469241773962805, 0.8469241773962805, 0.8469241773962805, 0.8469241773962805, 0.84620886981402, 0.84620886981402, 0.84620886981402, 0.8454935622317596, 0.8454935622317596, 0.8454935622317596, 0.8454935622317596, 0.8454935622317596, 0.8447782546494993, 0.8447782546494993, 0.8447782546494993, 0.8447782546494993, 0.844062947067239, 0.844062947067239, 0.844062947067239, 0.8433476394849786, 0.8433476394849786, 0.8433476394849786, 0.8426323319027181, 0.8426323319027181, 0.8419170243204578, 0.8419170243204578, 0.8419170243204578, 0.8419170243204578, 0.8419170243204578, 0.8419170243204578, 0.8412017167381974, 0.8412017167381974, 0.8412017167381974, 0.8412017167381974, 0.8404864091559371, 0.8404864091559371, 0.8404864091559371, 0.8404864091559371, 0.8397711015736766, 0.8397711015736766, 0.8397711015736766, 0.8390557939914163, 0.8390557939914163, 0.8390557939914163, 0.8390557939914163, 0.8390557939914163, 0.8383404864091559, 0.8383404864091559, 0.8383404864091559, 0.8383404864091559, 0.8383404864091559, 0.8383404864091559, 0.8383404864091559, 0.8369098712446352, 0.8369098712446352, 0.8369098712446352, 0.8369098712446352, 0.8369098712446352, 0.8361945636623748, 0.8361945636623748, 0.8361945636623748, 0.8361945636623748, 0.8354792560801144, 0.8354792560801144, 0.8354792560801144, 0.8354792560801144, 0.8354792560801144, 0.8347639484978541, 0.8347639484978541, 0.8347639484978541, 0.8340486409155937, 0.8340486409155937, 0.8340486409155937, 0.8333333333333334, 0.8333333333333334, 0.8326180257510729, 0.8326180257510729, 0.8311874105865522, 0.8311874105865522, 0.8311874105865522, 0.8311874105865522, 0.8311874105865522, 0.8304721030042919, 0.8304721030042919, 0.8297567954220315, 0.8297567954220315, 0.8297567954220315, 0.8297567954220315, 0.829041487839771, 0.8261802575107297, 0.8261802575107297, 0.8247496423462088, 0.8240343347639485, 0.8233190271816881, 0.8233190271816881, 0.8226037195994278, 0.8226037195994278, 0.8204577968526466, 0.8075822603719599]\n",
      "[114, 214, 197, 97, 190, 208, 146, 173, 221, 118, 160, 130, 104, 143, 193, 129, 212, 223, 134, 154, 222, 194, 167, 217, 152, 151, 140, 132, 99, 110, 149, 233, 226, 107, 137, 227, 218, 111, 198, 179, 183, 96, 169, 147, 192, 109, 161, 196, 153, 219, 127, 234, 123, 93, 139, 150, 209, 141, 211, 121, 203, 145, 135, 106, 163, 136, 158, 220, 177, 191, 205, 172, 231, 128, 125, 101, 184, 235, 133, 229, 182, 164, 207, 124, 202, 232, 185, 195, 216, 144, 178, 168, 165, 116, 113, 156, 120, 224, 189, 112, 157, 155, 228, 236, 98, 117, 187, 180, 102, 131, 215, 174, 238, 210, 230, 206, 162, 115, 103, 108, 204, 142, 200, 213, 175, 92, 159, 171, 105, 188, 170, 237, 181, 199, 176, 186, 166, 122, 91, 201, 138, 95, 148, 119, 100, 126, 225, 94]\n"
     ]
    }
   ],
   "source": [
    "def acc_ckpt(dir_name):\n",
    "\n",
    "    ckpt_list = os.listdir(dir_name)\n",
    "    print('model check list: {}'.format(ckpt_list))\n",
    "\n",
    "    epoch = []\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "\n",
    "    for ckpt_file in ckpt_list:\n",
    "        if ckpt_file.find('.ckpt') != -1:\n",
    "            ckpt = torch.load(os.path.join(dir_name, ckpt_file))\n",
    "            print('epoch: {}, train_acc: {}, test_acc: {}'.format(ckpt['epoch'], ckpt['train_acc'], ckpt['test_acc']))\n",
    "\n",
    "            epoch.append(ckpt['epoch'])\n",
    "            train_acc.append(ckpt['train_acc'])\n",
    "            test_acc.append(ckpt['test_acc'])\n",
    "\n",
    "    sorted_idx = np.argsort(test_acc)[::-1]\n",
    "    print([test_acc[i] for i in sorted_idx])\n",
    "    print([epoch[i] for i in sorted_idx])\n",
    "\n",
    "    return\n",
    "\n",
    "acc_ckpt(\"./models/20201103_235321\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
