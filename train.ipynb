{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.utils.data\n",
    "from torch.nn import DataParallel\n",
    "from datetime import datetime\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from config import BATCH_SIZE, PROPOSAL_NUM, SAVE_FREQ, LR, WD, resume, save_dir\n",
    "from core import model, dataset\n",
    "from core.utils import init_log, progress_bar\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'\n",
    "start_epoch = 1\n",
    "save_dir = os.path.join(save_dir, datetime.now().strftime('%Y%m%d_%H%M%S'))\n",
    "if os.path.exists(save_dir):\n",
    "    raise NameError('model dir exists!')\n",
    "os.makedirs(save_dir)\n",
    "logging = init_log(save_dir)\n",
    "_print = logging.info\n",
    "\n",
    "# read dataset\n",
    "trainset = dataset.CUB(root='./CUB_200_2011', is_train=True, data_len=None)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=8, drop_last=False)\n",
    "testset = dataset.CUB(root='./CUB_200_2011', is_train=False, data_len=None)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=8, drop_last=False)\n",
    "# define model\n",
    "net = model.attention_net(topN=PROPOSAL_NUM)\n",
    "if resume:\n",
    "    ckpt = torch.load(resume)\n",
    "    net.load_state_dict(ckpt['net_state_dict'])\n",
    "    start_epoch = ckpt['epoch'] + 1\n",
    "creterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# define optimizers\n",
    "raw_parameters = list(net.pretrained_model.parameters())\n",
    "part_parameters = list(net.proposal_net.parameters())\n",
    "concat_parameters = list(net.concat_net.parameters())\n",
    "partcls_parameters = list(net.partcls_net.parameters())\n",
    "\n",
    "raw_optimizer = torch.optim.SGD(raw_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n",
    "concat_optimizer = torch.optim.SGD(concat_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n",
    "part_optimizer = torch.optim.SGD(part_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n",
    "partcls_optimizer = torch.optim.SGD(partcls_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n",
    "schedulers = [MultiStepLR(raw_optimizer, milestones=[60, 100], gamma=0.1),\n",
    "              MultiStepLR(concat_optimizer, milestones=[60, 100], gamma=0.1),\n",
    "              MultiStepLR(part_optimizer, milestones=[60, 100], gamma=0.1),\n",
    "              MultiStepLR(partcls_optimizer, milestones=[60, 100], gamma=0.1)]\n",
    "net = net.cuda()\n",
    "net = DataParallel(net)\n",
    "\n",
    "for epoch in range(start_epoch, 500):\n",
    "    for scheduler in schedulers:\n",
    "        scheduler.step()\n",
    "\n",
    "    # begin training\n",
    "    _print('--' * 50)\n",
    "    net.train()\n",
    "    for i, data in enumerate(trainloader):\n",
    "        img, label = data[0].cuda(), data[1].cuda()\n",
    "        batch_size = img.size(0)\n",
    "        raw_optimizer.zero_grad()\n",
    "        part_optimizer.zero_grad()\n",
    "        concat_optimizer.zero_grad()\n",
    "        partcls_optimizer.zero_grad()\n",
    "\n",
    "        raw_logits, concat_logits, part_logits, _, top_n_prob = net(img)\n",
    "        part_loss = model.list_loss(part_logits.view(batch_size * PROPOSAL_NUM, -1),\n",
    "                                    label.unsqueeze(1).repeat(1, PROPOSAL_NUM).view(-1)).view(batch_size, PROPOSAL_NUM)\n",
    "        raw_loss = creterion(raw_logits, label)\n",
    "        concat_loss = creterion(concat_logits, label)\n",
    "        rank_loss = model.ranking_loss(top_n_prob, part_loss)\n",
    "        partcls_loss = creterion(part_logits.view(batch_size * PROPOSAL_NUM, -1),\n",
    "                                 label.unsqueeze(1).repeat(1, PROPOSAL_NUM).view(-1))\n",
    "\n",
    "        total_loss = raw_loss + rank_loss + concat_loss + partcls_loss\n",
    "        total_loss.backward()\n",
    "        raw_optimizer.step()\n",
    "        part_optimizer.step()\n",
    "        concat_optimizer.step()\n",
    "        partcls_optimizer.step()\n",
    "        progress_bar(i, len(trainloader), 'train')\n",
    "\n",
    "    if epoch % SAVE_FREQ == 0:\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        total = 0\n",
    "        net.eval()\n",
    "        for i, data in enumerate(trainloader):\n",
    "            with torch.no_grad():\n",
    "                img, label = data[0].cuda(), data[1].cuda()\n",
    "                batch_size = img.size(0)\n",
    "                _, concat_logits, _, _, _ = net(img)\n",
    "                # calculate loss\n",
    "                concat_loss = creterion(concat_logits, label)\n",
    "                # calculate accuracy\n",
    "                _, concat_predict = torch.max(concat_logits, 1)\n",
    "                total += batch_size\n",
    "                train_correct += torch.sum(concat_predict.data == label.data)\n",
    "                train_loss += concat_loss.item() * batch_size\n",
    "                progress_bar(i, len(trainloader), 'eval train set')\n",
    "\n",
    "        train_acc = float(train_correct) / total\n",
    "        train_loss = train_loss / total\n",
    "\n",
    "        _print(\n",
    "            'epoch:{} - train loss: {:.3f} and train acc: {:.3f} total sample: {}'.format(\n",
    "                epoch,\n",
    "                train_loss,\n",
    "                train_acc,\n",
    "                total))\n",
    "\n",
    "\t# evaluate on test set\n",
    "        test_loss = 0\n",
    "        test_correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(testloader):\n",
    "            with torch.no_grad():\n",
    "                img, label = data[0].cuda(), data[1].cuda()\n",
    "                batch_size = img.size(0)\n",
    "                _, concat_logits, _, _, _ = net(img)\n",
    "                # calculate loss\n",
    "                concat_loss = creterion(concat_logits, label)\n",
    "                # calculate accuracy\n",
    "                _, concat_predict = torch.max(concat_logits, 1)\n",
    "                total += batch_size\n",
    "                test_correct += torch.sum(concat_predict.data == label.data)\n",
    "                test_loss += concat_loss.item() * batch_size\n",
    "                progress_bar(i, len(testloader), 'eval test set')\n",
    "\n",
    "        test_acc = float(test_correct) / total\n",
    "        test_loss = test_loss / total\n",
    "        _print(\n",
    "            'epoch:{} - test loss: {:.3f} and test acc: {:.3f} total sample: {}'.format(\n",
    "                epoch,\n",
    "                test_loss,\n",
    "                test_acc,\n",
    "                total))\n",
    "\n",
    "\t# save model\n",
    "        net_state_dict = net.module.state_dict()\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.mkdir(save_dir)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc,\n",
    "            'net_state_dict': net_state_dict},\n",
    "            os.path.join(save_dir, '%03d.ckpt' % epoch))\n",
    "\n",
    "print('finishing training')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
